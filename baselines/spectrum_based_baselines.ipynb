{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time, json, sqlite3, re, difflib, numpy, cPickle as cp, glob, random, itertools, glob\n",
    "from copy import deepcopy\n",
    "import operator\n",
    "from math import sqrt\n",
    "import subprocess32 as subprocess\n",
    "sys.path.append('..')\n",
    "from util.helpers import make_dir_if_not_exists as mkdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_path = '../data/dataset.db'\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    cursor = c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#programs: 2167\n"
     ]
    }
   ],
   "source": [
    "# Load eval set\n",
    "eval_set = numpy.load('../data/eval_set.npy').item()\n",
    "bug_to_line_map = numpy.load('../data/bug_to_line_map.npy').item()\n",
    "\n",
    "eval_dict = {}\n",
    "for problem_id in eval_set:\n",
    "    for program_id, row in eval_set[problem_id].items():\n",
    "        eval_dict[program_id] = row\n",
    "\n",
    "eval_set_program_ids = set(eval_dict.keys())\n",
    "print '#programs:', len(eval_set_program_ids)\n",
    "\n",
    "TCNN_correct_classifications = numpy.load('../data/TCNN_correct_classifications.npy').item()\n",
    "\n",
    "eval_dict = {}\n",
    "for problem_id in eval_set:\n",
    "    for program_id, row in eval_set[problem_id].items():\n",
    "            eval_dict[program_id] = set(row[3])\n",
    "\n",
    "TCNN_wrong_classifications_list = numpy.load('../data/TCNN_wrong_classifications.npy')\n",
    "\n",
    "TCNN_wrong_classifications = {}\n",
    "for program_id, test_id in TCNN_wrong_classifications_list:\n",
    "    program_id = int(program_id)\n",
    "    if program_id not in TCNN_wrong_classifications:\n",
    "        TCNN_wrong_classifications[program_id] = set()\n",
    "    TCNN_wrong_classifications[program_id].add(test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048576 - set([10]) | 1048577 - set([8]) | 1064963 - set([24, 23, 22, 15]) | 1064961 - set([14]) | 1048585 - set([5, 6]) | 1048586 - set([10, 5]) | 1024011 - set([4, 6]) | 1064984 - set([6, 7]) | 1024025 - set([20, 21]) | 1024029 - set([8, 5]) |\n"
     ]
    }
   ],
   "source": [
    "# program_id, buggy location\n",
    "for key, value in eval_dict.items()[:10]:\n",
    "    print key, '-', value, '|',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_empty_lines(lines):\n",
    "    return [line for line in lines if len(line.strip()) > 0]\n",
    "\n",
    "def prepend_line_no(prog):\n",
    "    lines=prog.split('\\n')\n",
    "    lines = ['[%2d] %s' % (idx+1, line) for idx, line in enumerate(lines)]\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "def remove_all_white_space(line):\n",
    "    return ''.join(line.split())\n",
    "\n",
    "def normalize_brackets(program):\n",
    "    program = program.replace('\\r', '\\n')\n",
    "    lines = [line for line in program.split('\\n') if len(line.strip()) > 0]\n",
    "    \n",
    "    if len(lines) == 1:\n",
    "        raise ValueError()\n",
    "\n",
    "    for i in range(len(lines)-1, -1, -1):\n",
    "        line = lines[i]\n",
    "        wsr_line = remove_all_white_space(line)\n",
    "        if wsr_line == '}' or wsr_line == '}}' or wsr_line == '}}}' or wsr_line == '};' \\\n",
    "        or wsr_line == '}}}}' or wsr_line == '}}}}}' or wsr_line == '{' or wsr_line == '{{':\n",
    "            if i > 0:\n",
    "                lines[i-1] += ' ' + line.strip()\n",
    "                lines[i]    = ''\n",
    "            else:\n",
    "                # can't handle this case!\n",
    "                raise ValueError()\n",
    "                return ''\n",
    "\n",
    "    # Remove empty lines\n",
    "    for i in range(len(lines)-1, -1, -1):\n",
    "        if lines[i] == '':\n",
    "            del lines[i]\n",
    "\n",
    "    for line in lines:\n",
    "        assert(lines[i].strip() != '')\n",
    "\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "def get_program(program_id, flag_prepend_line_no=False, clean_up=False):\n",
    "    query='''SELECT program, problem_id FROM orgsource WHERE program_id=?;'''\n",
    "    global cursor\n",
    "\n",
    "    for row in cursor.execute(query, (program_id, )):\n",
    "        program = row[0].encode('utf-8', 'ignore')\n",
    "        problem_id = row[1]\n",
    "\n",
    "        if clean_up:\n",
    "            program = normalize_brackets(program)\n",
    "            program_lines = remove_empty_lines(program.replace('\\r', '\\n').split('\\n'))\n",
    "            program = '\\n'.join(program_lines)\n",
    "\n",
    "        if flag_prepend_line_no:\n",
    "            program = prepend_line_no(program)\n",
    "\n",
    "        return program, str(problem_id)\n",
    "    \n",
    "def get_program_test_info(program_id):\n",
    "    query='''SELECT problem_id, t.test_id, t.verdict FROM orgsource o INNER JOIN test_runs t \n",
    "            ON o.program_id=t.program_id WHERE o.program_id=?;'''\n",
    "\n",
    "    global cursor\n",
    "\n",
    "    rows = []\n",
    "    for row in cursor.execute(query, (program_id, )):\n",
    "        problem_id, test_id, verdict = row\n",
    "        rows.append((problem_id, test_id, verdict))\n",
    "    return rows\n",
    "    \n",
    "def get_test_count(problem_id):\n",
    "    query = '''SELECT test_cnt FROM problems WHERE problem_id=?'''\n",
    "    global cursor\n",
    "    for row in cursor.execute(query, (problem_id, )):\n",
    "        return row[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dir = '../data/eval-programs/'\n",
    "mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write programs to a directory\n",
    "for program_id in TCNN_correct_classifications:\n",
    "    program, problem_id = get_program(program_id, clean_up=True)\n",
    "    if not os.path.exists(os.path.join(output_dir, problem_id)):\n",
    "        mkdir(os.path.join(output_dir, problem_id))\n",
    "    with open(os.path.join(output_dir, problem_id, '{}.c'.format(program_id)), 'w') as f:\n",
    "        f.write(program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now run the following two commands in the ../data directory and wait for script to finish\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1 find tests -name '*.gc*' -delete\n",
    "#2 ./get_coverage.sh eval-programs\n",
    "#  NOTE: Make sure that there is no leading / after `./get_coverage.sh eval-programs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read gcov files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_coverage(gcov_file):\n",
    "    \n",
    "    def process_line(line):\n",
    "        tag, line_no, code = line.strip().split(':', 2)\n",
    "        return tag.strip(), int(line_no.strip()), code\n",
    "    \n",
    "    coverage = {}\n",
    "        \n",
    "    for idx, line in enumerate(gcov_file.split('\\n')):\n",
    "        if idx <= 4 or len(line.strip()) == 0:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            tag, line_no, code = process_line(line)\n",
    "        except:\n",
    "            print 'idx:', idx, 'line:', line\n",
    "            print line.strip().split(':', 2)\n",
    "            raise\n",
    "        assert idx!=5 or line_no==1, gcov_file\n",
    "        \n",
    "        if tag == '-':\n",
    "            continue\n",
    "        elif tag == '#####':\n",
    "            coverage[line_no] = 0\n",
    "        else:  \n",
    "            tag = int(tag) \n",
    "            coverage[line_no] = 1\n",
    "            \n",
    "    return coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files 11642 programs: 1449\n"
     ]
    }
   ],
   "source": [
    "# gcov doesn't run on programs which don't handle a run time exception!\n",
    "\n",
    "gcov_files, all_coverage = {}, {}\n",
    "done = 0\n",
    "for problem_id in os.listdir(output_dir):\n",
    "    gcov_files[problem_id] = {}\n",
    "    all_coverage[problem_id] = {}\n",
    "    for gcov_file in glob.glob(os.path.join('../data/tests/', problem_id, '*.gcov')):\n",
    "        with open(gcov_file, 'r') as f:\n",
    "            filename = gcov_file.split('/')[-1]\n",
    "            test_name, filename = filename.split('-')\n",
    "            filename = int(filename.split('.')[0])\n",
    "            if filename not in gcov_files[problem_id]:\n",
    "                gcov_files[problem_id][filename] = {}\n",
    "                all_coverage[problem_id][filename] = {}\n",
    "            coverage_file = f.read()\n",
    "            gcov_files[problem_id][filename][test_name] = coverage_file\n",
    "            all_coverage[problem_id][filename][test_name] = get_coverage(coverage_file)\n",
    "            done += 1\n",
    "            \n",
    "print 'files', done, 'programs:', sum([len(gcov_files[problem_id]) for problem_id in gcov_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect test execution information    \n",
    "test_execution_details = {}\n",
    "for problem_id in all_coverage:\n",
    "    test_execution_details[problem_id] = {}\n",
    "    for program_id in all_coverage[problem_id]:\n",
    "        test_execution_details[problem_id][program_id] = {}\n",
    "        for _, test_id, verdict in get_program_test_info(program_id):\n",
    "            test_execution_details[problem_id][program_id][test_id] = verdict\n",
    "    \n",
    "test_counts = {}\n",
    "for problem_id in test_execution_details:\n",
    "    test_counts[problem_id] = get_test_count(problem_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# eval_set_dict\n",
    "program_ids_with_coverage = set()\n",
    "\n",
    "for problem_id in all_coverage.keys():\n",
    "    for program_id in all_coverage[problem_id]:\n",
    "        program_ids_with_coverage.add(program_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select all passing test_ids per program\n",
    "passing_tests = {}\n",
    "for problem_id in test_execution_details:\n",
    "    for program_id in test_execution_details[problem_id]:\n",
    "        for test_id in test_execution_details[problem_id][program_id]:\n",
    "            if test_execution_details[problem_id][program_id][test_id]:\n",
    "                if program_id not in passing_tests:\n",
    "                    passing_tests[program_id] = []\n",
    "                passing_tests[program_id].append(test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1449\n"
     ]
    }
   ],
   "source": [
    "selected_passing_tests = {}\n",
    "for program_id in passing_tests:\n",
    "    random.seed(program_id)\n",
    "    selected_passing_tests[program_id] = random.choice(passing_tests[program_id])\n",
    "    \n",
    "print len(selected_passing_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_scores(af, ap, nf, np):\n",
    "    tarantula, ochiai = {}, {}\n",
    "    for key in af:\n",
    "        afv, apv, nfv, npv = af[key], ap[key], nf[key], np[key]\n",
    "        try:\n",
    "            tarantula[key] = (afv/(afv+nfv)) / ( (afv/(afv+nfv)) + (apv/(apv+npv)) )\n",
    "        except: \n",
    "            tarantula[key] = 0\n",
    "        \n",
    "        try:\n",
    "            ochiai[key] = afv / sqrt( (afv + nfv) * (afv + apv) )\n",
    "        except:\n",
    "            ochiai[key] = 0\n",
    "            \n",
    "    sorted_tarantula = sorted(tarantula.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    sorted_ochiai = sorted(ochiai.items(), key=operator.itemgetter(1), reverse=True)    \n",
    "    return map(lambda (x,y):x, sorted_tarantula), map(lambda (x,y):x, sorted_ochiai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using one passing test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_faulty_lines = {}\n",
    "faulty_lines_found = { 'tarantula':{10:{}, 5:{}, 1:{}}, 'ochiai':{10:{}, 5:{}, 1:{}} }\n",
    "\n",
    "pairs_localized = { 'tarantula':{10:set(), 5:set(), 1:set()}, 'ochiai':{10:set(), 5:set(), 1:set()} }\n",
    "pairs_missed = { 'tarantula':{10:set(), 5:set(), 1:set()}, 'ochiai':{10:set(), 5:set(), 1:set()} }\n",
    "programs_localized = { 'tarantula':{10:set(), 5:set(), 1:set()}, 'ochiai':{10:set(), 5:set(), 1:set()} }\n",
    "\n",
    "skipped = []\n",
    "continue_1 = 0\n",
    "\n",
    "all_eval_programs = set()\n",
    "coverage_not_found = set()\n",
    "\n",
    "for problem_id in all_coverage.keys():\n",
    "    \n",
    "    for program_id in all_coverage[problem_id]:\n",
    "        \n",
    "        if program_id not in all_faulty_lines:\n",
    "            all_faulty_lines[program_id] = {}\n",
    "        \n",
    "        for test_id in all_coverage[problem_id][program_id]:\n",
    "            \n",
    "            # passing test, continue\n",
    "            if test_execution_details[problem_id][program_id][test_id]:  \n",
    "                continue\n",
    "                \n",
    "            # TCNN made a wrong prediction, continue\n",
    "            if program_id in TCNN_wrong_classifications and '{}{}'.format(problem_id,test_id) in TCNN_wrong_classifications[program_id]:\n",
    "                continue\n",
    "                    \n",
    "            if program_id in bug_to_line_map:\n",
    "                try:\n",
    "                    all_faulty_lines[program_id][test_id] = deepcopy(bug_to_line_map[program_id]['{}{}'.format(problem_id,test_id)])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "            else:\n",
    "                try:\n",
    "                    all_faulty_lines[program_id][test_id] = eval_dict[program_id]\n",
    "                except:\n",
    "                    continue\n",
    "                \n",
    "            assert len(all_faulty_lines[program_id][test_id])>0, program_id\n",
    "            \n",
    "            all_eval_programs.add(program_id)\n",
    "                \n",
    "            for tech in ['tarantula', 'ochiai']:\n",
    "                for each in [10,5,1]:\n",
    "                    if program_id not in faulty_lines_found[tech][each]:\n",
    "                        faulty_lines_found[tech][each][program_id] = {test_id:set()}\n",
    "                    else:\n",
    "                        assert test_id not in faulty_lines_found[tech][each][program_id]\n",
    "                        faulty_lines_found[tech][each][program_id][test_id] = set()\n",
    "\n",
    "            try:\n",
    "                failing_coverage = all_coverage[problem_id][program_id][test_id]\n",
    "                passing_test_id = selected_passing_tests[program_id]\n",
    "                passing_coverage = all_coverage[problem_id][program_id][passing_test_id]\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            af, ap, nf, np = {}, {}, {}, {}\n",
    "\n",
    "            for coverage, verdict in zip([failing_coverage, passing_coverage],[0,1]):\n",
    "                for key, appearance in coverage.items():\n",
    "                    appearance = float(appearance)\n",
    "                    af[key] = abs(appearance * (verdict-1)) if key not in af else af[key] + abs(appearance * (verdict-1))\n",
    "                    ap[key] = abs(appearance * verdict) if key not in ap else ap[key] + abs(appearance * verdict)\n",
    "                    nf[key] = abs((appearance-1) * (verdict-1)) if key not in nf else nf[key] + abs(appearance * (verdict-1))\n",
    "                    np[key] = abs((appearance-1) * verdict) if key not in np else np[key] + abs(appearance * verdict)\n",
    "                    \n",
    "            sorted_tarantula, sorted_ochiai = get_scores(af, ap, nf, np)\n",
    "            for tech, top_k_lines in zip(['tarantula', 'ochiai'], [sorted_tarantula, sorted_ochiai]):\n",
    "\n",
    "                for top_k in [10,5,1]:\n",
    "                    some_line_found = False\n",
    "                    for line in all_faulty_lines[program_id][test_id]:\n",
    "                        if line in top_k_lines[:top_k]:\n",
    "                            faulty_lines_found[tech][top_k][program_id][test_id].add(line)\n",
    "                            some_line_found = True\n",
    "\n",
    "                    if some_line_found:\n",
    "                        pairs_localized[tech][top_k].add((program_id, test_id))\n",
    "                        programs_localized[tech][top_k].add((program_id))\n",
    "                    else:\n",
    "                        pairs_missed[tech][top_k].add((program_id, test_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#all_programs: 1449 programs localized:\n",
      "TARANTULA\n",
      "10  958 66.11%\n",
      " 5  461 31.82%\n",
      " 1    6 0.41%\n",
      "\n",
      "OCHIAI\n",
      "10 1137 78.47%\n",
      " 5  811 55.97%\n",
      " 1  217 14.98%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print '#all_programs:', len(TCNN_correct_classifications), 'programs localized:'\n",
    "for tech in ['tarantula', 'ochiai']:\n",
    "    print tech.upper()\n",
    "    for top_k in [10,5,1]:\n",
    "        print '%2d' % top_k, '%4d' % len(programs_localized[tech][top_k]), '%4.2f%%' % (100.0*len(programs_localized[tech][top_k])/len(TCNN_correct_classifications))\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using all passing tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_faulty_lines = {}\n",
    "faulty_lines_found = { 'tarantula':{10:{}, 5:{}, 1:{}}, 'ochiai':{10:{}, 5:{}, 1:{}} }\n",
    "\n",
    "pairs_localized = { 'tarantula':{10:set(), 5:set(), 1:set()}, 'ochiai':{10:set(), 5:set(), 1:set()} }\n",
    "pairs_missed = { 'tarantula':{10:set(), 5:set(), 1:set()}, 'ochiai':{10:set(), 5:set(), 1:set()} }\n",
    "programs_localized = { 'tarantula':{10:set(), 5:set(), 1:set()}, 'ochiai':{10:set(), 5:set(), 1:set()} }\n",
    "\n",
    "skipped = []\n",
    "\n",
    "all_eval_programs = set()\n",
    "coverage_not_found = set()\n",
    "\n",
    "for problem_id in all_coverage.keys():\n",
    "    for program_id in all_coverage[problem_id]:\n",
    "        \n",
    "        if program_id not in all_faulty_lines:\n",
    "            all_faulty_lines[program_id] = {}\n",
    "        \n",
    "        for test_id in all_coverage[problem_id][program_id]:\n",
    "            \n",
    "            if test_execution_details[problem_id][program_id][test_id]:\n",
    "                continue\n",
    "                \n",
    "            if program_id in TCNN_wrong_classifications and '{}{}'.format(problem_id,test_id) in TCNN_wrong_classifications[program_id]:\n",
    "                continue\n",
    "                    \n",
    "            if program_id in bug_to_line_map:\n",
    "                try:\n",
    "                    all_faulty_lines[program_id][test_id] = deepcopy(bug_to_line_map[program_id]['{}{}'.format(problem_id,test_id)])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "            else:\n",
    "                all_faulty_lines[program_id][test_id] = eval_dict[program_id]\n",
    "                \n",
    "            assert len(all_faulty_lines[program_id][test_id])>0, program_id\n",
    "            \n",
    "            all_eval_programs.add(program_id)\n",
    "                \n",
    "            for tech in ['tarantula', 'ochiai']:\n",
    "                for each in [10,5,1]:\n",
    "                    if program_id not in faulty_lines_found[tech][each]:\n",
    "                        faulty_lines_found[tech][each][program_id] = {test_id:set()}\n",
    "                    else:\n",
    "                        assert test_id not in faulty_lines_found[tech][each][program_id]\n",
    "                        faulty_lines_found[tech][each][program_id][test_id] = set()\n",
    "\n",
    "            af, ap, nf, np = {}, {}, {}, {}\n",
    "            for tid in all_coverage[problem_id][program_id]:\n",
    "                verdict = test_execution_details[problem_id][program_id][tid]\n",
    "                coverage = all_coverage[problem_id][program_id][tid]\n",
    "                if not (verdict or tid == test_id):\n",
    "                    continue\n",
    "\n",
    "                for key, appearance in coverage.items():\n",
    "                    appearance = float(appearance)\n",
    "                    af[key] = abs(appearance * (verdict-1)) if key not in af else af[key] + abs(appearance * (verdict-1))\n",
    "                    ap[key] = abs(appearance * verdict) if key not in ap else ap[key] + abs(appearance * verdict)\n",
    "                    nf[key] = abs((appearance-1) * (verdict-1)) if key not in nf else nf[key] + abs(appearance * (verdict-1))\n",
    "                    np[key] = abs((appearance-1) * verdict) if key not in np else np[key] + abs(appearance * verdict)\n",
    "\n",
    "            sorted_tarantula, sorted_ochiai = get_scores(af, ap, nf, np)\n",
    "\n",
    "\n",
    "            for tech, top_k_lines in zip(['tarantula', 'ochiai'], [sorted_tarantula, sorted_ochiai]):\n",
    "\n",
    "                for top_k in [10,5,1]:\n",
    "                    some_line_found = False\n",
    "                    for line in all_faulty_lines[program_id][test_id]:\n",
    "                        if line in top_k_lines[:top_k]:\n",
    "                            faulty_lines_found[tech][top_k][program_id][test_id].add(line)\n",
    "                            some_line_found = True\n",
    "\n",
    "                    if some_line_found:\n",
    "                        pairs_localized[tech][top_k].add((program_id, test_id))\n",
    "                        programs_localized[tech][top_k].add((program_id))\n",
    "                    else:\n",
    "                        pairs_missed[tech][top_k].add((program_id, test_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#all_programs: 1449 programs localized:\n",
      "TARANTULA\n",
      "10 1151 79.43%\n",
      " 5  809 55.83%\n",
      " 1  346 23.88%\n",
      "\n",
      "OCHIAI\n",
      "10 1151 79.43%\n",
      " 5  835 57.63%\n",
      " 1  385 26.57%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print '#all_programs:', len(TCNN_correct_classifications), 'programs localized:'\n",
    "for tech in ['tarantula', 'ochiai']:\n",
    "    print tech.upper()\n",
    "    for top_k in [10,5,1]:\n",
    "        print '%2d' % top_k, '%4d' % len(programs_localized[tech][top_k]), '%4.2f%%' % (100.0*len(programs_localized[tech][top_k])/len(TCNN_correct_classifications))\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpu-tf-1.0.1]",
   "language": "python",
   "name": "conda-env-cpu-tf-1.0.1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
