{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Embedding\n",
    "from keras import backend as K\n",
    "\n",
    "import os, sys, glob, numpy as np, sqlite3, json, random, difflib, cPickle as cp\n",
    "from copy import deepcopy\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import classification_report\n",
    "sys.path.append('..')\n",
    "from util.helpers import Tree_Dataset as Dataset, make_dir_if_not_exists as mkdir, get_rev_dict, prepend_line_numbers\n",
    "from util.ast_helpers import get_subtree_list\n",
    "\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_org_model(max_subtrees, max_nodes, embedding_dim, vocab_size, best_checkpoint):\n",
    "    program_input = Input(shape=(max_subtrees, max_nodes), dtype='int32', name='program')\n",
    "    embedded_program = Embedding(output_dim=embedding_dim, input_dim=vocab_size, name='program_embedding')(program_input)\n",
    "\n",
    "    # Use convolution over program input\n",
    "    base = Conv2D(64, (1, 1), padding='same', activation='relu', name='base')(embedded_program)\n",
    "    tower_1 = Conv2D(64, (1, max_nodes), padding='valid', activation='relu', name='tower1')(base)\n",
    "    tower_2 = Conv2D(64, (3, max_nodes), strides=(3, 1), padding='valid', activation='relu', name='tower2')(base)\n",
    "    program_features = keras.layers.concatenate([tower_1, tower_2], axis=1)\n",
    "    program_vector = Flatten()(program_features)\n",
    "\n",
    "    # embed test_id, and problem_id input\n",
    "    problem_id_input = Input(shape=(1,), dtype='int32', name='problem_id')\n",
    "    embedded_problem_id = Embedding(output_dim=5, input_dim=cnt_problem_ids, name='problem_id_embedding')(problem_id_input)\n",
    "    embedded_problem_id = keras.layers.Reshape((5,))(embedded_problem_id)\n",
    "\n",
    "    test_id_input = Input(shape=(1,), dtype='int32', name='test_id')\n",
    "    embedded_test_id = Embedding(output_dim=5, input_dim=test_suite_size, name='test_id_embedding')(test_id_input)\n",
    "    embedded_test_id = keras.layers.Reshape((5,))(embedded_test_id)\n",
    "\n",
    "    merged = keras.layers.concatenate([program_vector, embedded_test_id, embedded_problem_id])\n",
    "\n",
    "    hidden = Dense(128, activation='relu')(merged)\n",
    "    hidden = Dense(64, activation='relu')(hidden)\n",
    "    hidden = Dense(32, activation='relu')(hidden)\n",
    "    logits = Dense(2)(hidden)\n",
    "    output = keras.layers.Softmax()(logits)\n",
    "    org_model = Model(inputs=[program_input, problem_id_input, test_id_input], outputs=output)\n",
    "\n",
    "    print 'original model summary!'\n",
    "    org_model.summary()\n",
    "    org_model.load_weights(best_checkpoint, by_name=True, skip_mismatch=False, reshape=False)\n",
    "    org_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return org_model\n",
    "\n",
    "def get_emb_model(max_subtrees, max_nodes, embedding_dim, vocab_size):\n",
    "    program_input = Input(shape=(max_subtrees, max_nodes), dtype='int32', name='program')\n",
    "    output_embedded_program = Embedding(output_dim=embedding_dim, input_dim=vocab_size, name='program_embedding')(program_input)\n",
    "    emb_model = Model(inputs=program_input, outputs=output_embedded_program)\n",
    "    \n",
    "    emb_model.summary()\n",
    "    return emb_model\n",
    "\n",
    "def get_rest_of_the_model(max_subtrees, max_nodes, embedding_dim, vocab_size):\n",
    "    embedded_program_input = Input(shape=(max_subtrees, max_nodes, embedding_dim))\n",
    "\n",
    "    base = Conv2D(64, (1, 1), padding='same', activation='relu', name='base')(embedded_program_input)\n",
    "    tower_1 = Conv2D(64, (1, max_nodes), padding='valid', activation='relu', name='tower1')(base)\n",
    "    tower_2 = Conv2D(64, (3, max_nodes), strides=(3, 1), padding='valid', activation='relu', name='tower2')(base)\n",
    "    program_features = keras.layers.concatenate([tower_1, tower_2], axis=1)\n",
    "    program_vector = Flatten()(program_features)\n",
    "\n",
    "    problem_id_input = Input(shape=(1,), dtype='int32', name='problem_id')\n",
    "    embedded_problem_id = Embedding(output_dim=5, input_dim=cnt_problem_ids, name='problem_id_embedding')(problem_id_input)\n",
    "    embedded_problem_id = keras.layers.Reshape((5,))(embedded_problem_id)\n",
    "\n",
    "    test_id_input = Input(shape=(1,), dtype='int32', name='test_id')\n",
    "    embedded_test_id = Embedding(output_dim=5, input_dim=test_suite_size, name='test_id_embedding')(test_id_input)\n",
    "    embedded_test_id = keras.layers.Reshape((5,))(embedded_test_id)\n",
    "\n",
    "    merged = keras.layers.concatenate([program_vector, embedded_test_id, embedded_problem_id])\n",
    "\n",
    "    hidden = Dense(128, activation='relu')(merged)\n",
    "    hidden = Dense(64, activation='relu')(hidden)\n",
    "    hidden = Dense(32, activation='relu')(hidden)\n",
    "    logits = Dense(2)(hidden)\n",
    "    output = keras.layers.Softmax()(logits)\n",
    "    model = Model(inputs=[embedded_program_input, problem_id_input, test_id_input], outputs=output)\n",
    "    print 'rest of the model summary!'\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def prepare_failing_data(data_directory, program_ids_for_eval):\n",
    "    '''collect negative examples (which fail a test case)'''\n",
    "\n",
    "    neg_example_indices = []\n",
    "    for idx, program_id in enumerate(program_ids):\n",
    "        # each program appears with many test cases, some of which can pass\n",
    "        if program_id in program_ids_for_eval and not verdicts[idx]:\n",
    "            neg_example_indices.append(idx)\n",
    "    print 'len(neg_example_indices):', len(neg_example_indices)\n",
    "\n",
    "    neg_program_ids, neg_programs, neg_problem_ids, neg_test_ids,  neg_verdicts, neg_buggy_subtrees = [], [], [], [], [], []\n",
    "    done = set()\n",
    "    for idx in neg_example_indices:\n",
    "        neg_program_ids.append(program_ids[idx])\n",
    "        neg_programs.append(programs[idx])\n",
    "        neg_problem_ids.append(problem_ids[idx])\n",
    "        neg_test_ids.append(test_ids[idx])\n",
    "        neg_verdicts.append(verdicts[idx])\n",
    "        neg_buggy_subtrees.append(buggy_subtrees[idx])\n",
    "        done.add('{}_{}'.format(program_ids[idx], test_ids[idx]))\n",
    "    \n",
    "    print 'len(done):', len(done)\n",
    "\n",
    "    # to make things compatible with older negative subtree processing\n",
    "    with open(os.path.join(data_directory, 'examples-eval.pkl'), 'r') as f:\n",
    "        eval_examples = cp.load(f)\n",
    "\n",
    "    _, eval_program_ids, _, _, _, eval_buggy_subtrees = zip(*eval_examples)\n",
    "\n",
    "    pid_to_buggy_subtree_map = {}\n",
    "    for eval_program_id, eval_buggy_subtree in zip(eval_program_ids, eval_buggy_subtrees):\n",
    "        pid_to_buggy_subtree_map[eval_program_id] = eval_buggy_subtree\n",
    "        \n",
    "    to_delete = []\n",
    "    neg_buggy_line_to_subtrees = []\n",
    "    for idx, neg_program_id in enumerate(neg_program_ids):\n",
    "        try:\n",
    "            neg_buggy_line_to_subtrees.append(pid_to_buggy_subtree_map[neg_program_id])\n",
    "        except KeyError:\n",
    "            to_delete.append(idx)\n",
    "            \n",
    "    print len(to_delete), len(neg_buggy_line_to_subtrees)\n",
    "    assert len(neg_program_ids) == len(neg_buggy_line_to_subtrees), len(neg_buggy_line_to_subtrees)\n",
    "\n",
    "    return neg_program_ids, neg_programs, neg_problem_ids, neg_test_ids,  neg_verdicts, neg_buggy_subtrees, neg_buggy_line_to_subtrees\n",
    "\n",
    "def get_negative_example(evaluation_dataset, index):\n",
    "    neg_program_ids, neg_programs, neg_problem_ids, neg_test_ids, neg_verdicts, neg_buggy_subtrees, neg_buggy_line_to_subtrees = evaluation_dataset\n",
    "    neg_program_id = neg_program_ids[index]\n",
    "    neg_program = neg_programs[index]\n",
    "    neg_problem_id = neg_problem_ids[index]\n",
    "    neg_test_id = neg_test_ids[index]\n",
    "    neg_verdict = neg_verdicts[index]\n",
    "    neg_buggy_subtree = neg_buggy_subtrees[index]\n",
    "    neg_buggy_line_to_subtree = neg_buggy_line_to_subtrees[index]\n",
    "    return neg_program_id, neg_program, neg_problem_id, neg_test_id, neg_verdict, neg_buggy_subtree, neg_buggy_line_to_subtree\n",
    "\n",
    "def get_models_result_for_example(example_tuple, org_model, emb_model, model):\n",
    "    neg_program_id, neg_program, neg_problem_id, neg_test_id, neg_verdict, neg_buggy_subtree, neg_buggy_line_to_subtree = example_tuple\n",
    "    example_x = [ np.array([neg_program]), np.array([[neg_problem_id]]), np.array([[neg_test_id]]) ]\n",
    "    example_y = keras.utils.to_categorical([neg_verdict], num_classes=2)\n",
    "\n",
    "    emb_program = emb_model.predict([example_x[0]])\n",
    "\n",
    "    test_x = [emb_program, example_x[1], example_x[2]]\n",
    "    test_y = example_y\n",
    "\n",
    "    model_result =  model.predict(test_x, verbose=False)\n",
    "    org_model_result = org_model.predict(example_x, verbose=False)\n",
    "\n",
    "    return model_result[0], org_model_result[0]\n",
    "\n",
    "def genetate_classification_report(evaluation_dataset, org_model, emb_model, model):\n",
    "\n",
    "    org_model_Y_pred, model_Y_pred = [], []\n",
    "    neg_program_ids, neg_programs, neg_problem_ids, neg_test_ids, neg_verdicts, neg_buggy_subtrees, neg_buggy_line_to_subtrees = evaluation_dataset\n",
    "    todo_cnt = len(neg_program_ids)\n",
    "    \n",
    "    for idx in range(test_cnt):\n",
    "        neg_program_id, neg_program, neg_problem_id, neg_test_id, neg_verdict, \\\n",
    "        neg_buggy_subtree, neg_buggy_line_to_subtree = get_negative_example(evaluation_dataset, idx)\n",
    "        neg_problem_id = rev_problem_id_dict[neg_problem_id]\n",
    "\n",
    "        example_x = [ np.array([neg_program]), np.array([[neg_problem_id]]), np.array([[neg_test_id]]) ]\n",
    "        example_y = keras.utils.to_categorical([neg_verdict], num_classes=2)\n",
    "\n",
    "        emb_program = emb_model.predict([example_x[0]])\n",
    "        test_x = [emb_program, example_x[1], example_x[2]]\n",
    "        test_y = example_y\n",
    "    \n",
    "        model_Y_pred.append(np.squeeze(model.predict(test_x, verbose=False)))\n",
    "        org_model_Y_pred.append(np.squeeze(org_model.predict(example_x, verbose=False)))\n",
    "\n",
    "        print 'new model results:'\n",
    "        model_Y_pred = np.argmax(model_Y_pred, axis=1)\n",
    "        print '#correct predictions:', np.sum(neg_verdicts[:test_cnt] == model_Y_pred)\n",
    "        print(classification_report(neg_verdicts[:test_cnt], model_Y_pred))\n",
    "\n",
    "        print '\\norg model results:'\n",
    "        org_model_Y_pred = np.argmax(org_model_Y_pred, axis=1)\n",
    "        print '#correct predictions:', np.sum(neg_verdicts[:test_cnt] == org_model_Y_pred)\n",
    "        print(classification_report(neg_verdicts[:test_cnt], org_model_Y_pred))\n",
    "\n",
    "################################# attribution helpers\n",
    "\n",
    "# original model\n",
    "global_embedded_incorrect_programs_cache = {}\n",
    "def get_embedded_program(session, emb_model, program, program_id):\n",
    "    if program_id is None:\n",
    "        emb_program = emb_model.predict([program])\n",
    "        return emb_program\n",
    "    \n",
    "    global global_embedded_incorrect_programs_cache\n",
    "    if program_id not in global_embedded_incorrect_programs_cache:\n",
    "        emb_program = emb_model.predict([program])\n",
    "        global_embedded_incorrect_programs_cache[program_id] = emb_program\n",
    "    return global_embedded_incorrect_programs_cache[program_id]\n",
    "\n",
    "# emb model\n",
    "def make_predictions_and_gradients(session, model, softmax_output, label_gradients):\n",
    "    feed_list = [model.input[0], model.input[1], model.input[2], target_label_one_hot]\n",
    "    run_graph = session.make_callable([softmax_output, label_gradients], feed_list=feed_list)\n",
    "\n",
    "    def preds_and_grads_fn(emb_program, example_x, example_y):\n",
    "        softmax_predictions_out, label_gradients_out = run_graph(emb_program, example_x[1], example_x[2], example_y)\n",
    "        return softmax_predictions_out, label_gradients_out\n",
    "\n",
    "    return preds_and_grads_fn\n",
    "\n",
    "def top_label_id_and_score(emb_program, example_x, preds_and_grads_fn):\n",
    "    dummy_target_label_index = 0\n",
    "    dummy_train_y = keras.utils.to_categorical(dummy_target_label_index, num_classes=2)\n",
    "    preds, _ = preds_and_grads_fn(emb_program, example_x, [dummy_train_y])\n",
    "    index = np.argmax(preds[0])\n",
    "    return index, preds[0][index]\n",
    "\n",
    "def integrated_gradients(emb_program, example_x, example_y, predictions_and_gradients, emb_baseline, steps=100):\n",
    "    inp = emb_program\n",
    "    baseline = emb_baseline\n",
    "\n",
    "    if baseline is None:\n",
    "        baseline = 0*inp\n",
    "    assert baseline.shape == inp.shape, 'baseline.shape:{}, inp.shape:{}'.format(baseline.shape, inp.shape)\n",
    "\n",
    "    # Scale input and compute gradients.\n",
    "    scaled_inputs = [baseline + (float(i)/steps)*(inp-baseline) for i in range(0, steps+1)]\n",
    "    predictions, grads = [], []\n",
    "    for scaled_input in scaled_inputs:\n",
    "        top_label_id, score = top_label_id_and_score(scaled_input, example_x, predictions_and_gradients)\n",
    "        prediction, grad = predictions_and_gradients(scaled_input, example_x, example_y)  # shapes: <steps+1>, <steps+1, inp.shape>\n",
    "        predictions.append(prediction)\n",
    "        grads.append(grad)\n",
    "\n",
    "    avg_grads = np.average(np.array(grads[:-1]), axis=0)\n",
    "    assert np.shape(avg_grads) == np.shape(emb_program), 'avg_grads shape:{}, inp shape:{}'.format(np.shape(avg_grads), np.shape(emb_program))\n",
    "    integrated_gradients_value = (inp-baseline)*avg_grads  # shape: <inp.shape>\n",
    "    return integrated_gradients_value, np.squeeze(np.array(predictions))\n",
    "\n",
    "################################################# other helper functions\n",
    "\n",
    "def get_id_map(ast, program_id=None):\n",
    "    '''shuffles ids before assigning them indices using \n",
    "    program_id as randomness seed if program_id is not None'''\n",
    "    \n",
    "    ids = []\n",
    "    for subtree, coord in ast:\n",
    "        for node in subtree:\n",
    "            if '_<id>_' in node and '@' in node:\n",
    "                org_id = node.split('_<id>_')[1].split('@')[0]\n",
    "                if org_id not in ids:\n",
    "                    ids.append(org_id)\n",
    "                    \n",
    "    if program_id is not None:\n",
    "        random.seed(program_id)\n",
    "        random.shuffle(ids)\n",
    "\n",
    "    id_map = {}\n",
    "    for id_ in ids:\n",
    "        id_map[id_] = len(id_map)\n",
    "    return id_map\n",
    "\n",
    "def normalize_ids(ast, id_map):\n",
    "    new_ast = []\n",
    "    for subtree, coord in ast:\n",
    "        new_subtree = []\n",
    "        for node in subtree:\n",
    "            if '_<id>_' in node and '@' in node:\n",
    "                org_id = node.split('_<id>_')[1].split('@')[0]\n",
    "                new_subtree.append(node.replace('_<id>_' + org_id + '@', '_<id>_' + str(id_map[org_id]) + '@'))\n",
    "            else:\n",
    "                new_subtree.append(node)\n",
    "        assert len(new_subtree) == len(subtree)\n",
    "        new_ast.append((new_subtree, coord))\n",
    "    return new_ast\n",
    "\n",
    "\n",
    "def vectorize_subtree_list_ast(_tl_dict, subtree_list_ast, max_subtrees_per_program, max_nodes_per_subtree, buggy_line):\n",
    "    if len(subtree_list_ast) > max_subtrees_per_program:\n",
    "        return None, None\n",
    "    \n",
    "    vec_ast = []\n",
    "    buggy_subtree = None\n",
    "    for idx, (subtree, coord) in enumerate(subtree_list_ast):\n",
    "        if buggy_subtree is None:\n",
    "            line, char = map(int, coord.split(':'))\n",
    "            if line == buggy_line: buggy_subtree = idx\n",
    "        vec_subtree = []\n",
    "        for token in subtree:\n",
    "            vec_subtree.append(_tl_dict[token])\n",
    "        vec_ast.append(vec_subtree)\n",
    "        \n",
    "        if len(vec_subtree) > max_nodes_per_subtree:\n",
    "            return None, None\n",
    "    return vec_ast, buggy_subtree\n",
    "\n",
    "\n",
    "def load_all_correct_programs(db_path, problem_id_set):\n",
    "    query='''SELECT p.program_id, program, user_id, subtree_list_ast_without_leaves, time_stamp FROM\n",
    "            programs p INNER JOIN orgsource o ON o.program_id = p.program_id\n",
    "            INNER JOIN test_run_summary trs ON trs.program_id = p.program_id\n",
    "            WHERE trs.verdict=\"ALL_PASS\" AND problem_id=?;'''\n",
    "\n",
    "    correct_programs = {}\n",
    "\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        c = conn.cursor()\n",
    "\n",
    "        for problem_id in problem_id_set:\n",
    "            correct_programs[problem_id] = []\n",
    "            vectorization_errors = 0\n",
    "            size_mismatch_errors = 0\n",
    "\n",
    "            for row in c.execute(query, (problem_id,)):\n",
    "                program_id, program, user_id, subtree_list_ast, time_stamp = row\n",
    "                subtree_list_ast = json.loads(subtree_list_ast)\n",
    "                program = program.encode('utf-8','ignore')\n",
    "\n",
    "                id_map = get_id_map(subtree_list_ast, program_id=program_id)\n",
    "                norm_id_subtree_list_ast = normalize_ids(subtree_list_ast, id_map)\n",
    "                try:\n",
    "                    vec_ast, buggy_subtree = vectorize_subtree_list_ast(tl_dict, norm_id_subtree_list_ast, dataset.max_subtrees_per_program, dataset.max_nodes_per_subtree, buggy_line=0)\n",
    "                except KeyError:\n",
    "                    vectorization_errors += 1\n",
    "                \n",
    "                if vec_ast is not None:\n",
    "                    correct_programs[problem_id].append((program_id, program, user_id, time_stamp, id_map, vec_ast))\n",
    "                else:\n",
    "                    size_mismatch_errors += 1\n",
    "\n",
    "            print 'problem_id:', problem_id, '#correct_programs:', len(correct_programs[problem_id]),\n",
    "            print 'vectorization_errors:', vectorization_errors, 'size_mismatch_errors:', size_mismatch_errors\n",
    "\n",
    "        c.close()\n",
    "    return correct_programs\n",
    "\n",
    "def get_all_correct_program_embeddings(correct_programs):\n",
    "    correct_program_embeddings = {}\n",
    "    correct_program_id_map = {}\n",
    "    _user_indices = {}\n",
    "    for problem_id in correct_programs:\n",
    "        _user_indices[problem_id] = {}\n",
    "        correct_program_id_map[problem_id] = []\n",
    "        ast_list = []\n",
    "        for idx, (program_id, program, user_id, time_stamp, id_map, vec_ast) in enumerate(correct_programs[problem_id]):\n",
    "            ast_list.append(vec_ast)\n",
    "            correct_program_id_map[problem_id].append(program_id)\n",
    "            if user_id not in _user_indices[problem_id]:\n",
    "                _user_indices[problem_id][user_id] = set()\n",
    "            _user_indices[problem_id][user_id].add(idx)\n",
    "            \n",
    "        ast_batch, _, _ = dataset.prepare_batch(ast_list)\n",
    "        embeddings_batch = get_embedded_program(sess, emb_model, ast_batch, None)\n",
    "        correct_program_embeddings[problem_id] = embeddings_batch\n",
    "        correct_program_id_map[problem_id] = np.array(correct_program_id_map[problem_id])\n",
    "        print problem_id, len(correct_program_embeddings[problem_id]), len(_user_indices[problem_id])\n",
    "\n",
    "    return correct_program_embeddings, correct_program_id_map, _user_indices\n",
    "\n",
    "def get_correct_embeddings(problem_id, user_id_to_exclude, in_time_stamp=None):\n",
    "    global _user_indices, correct_program_embeddings, correct_programs\n",
    "    \n",
    "    if user_id_to_exclude is not None and user_id_to_exclude in _user_indices[problem_id]:\n",
    "        indices_to_exclude = deepcopy(_user_indices[problem_id][user_id_to_exclude])\n",
    "    else:\n",
    "        indices_to_exclude = set()\n",
    "            \n",
    "    if in_time_stamp is not None:\n",
    "        for problem_id in correct_programs:\n",
    "            for idx, (program_id, _, _, time_stamp, _, _) in enumerate(correct_programs[problem_id]):\n",
    "                if time_stamp > in_time_stamp:\n",
    "                    indices_to_exclude.add(idx)\n",
    "\n",
    "    all_indices = set(range(len(correct_program_embeddings[problem_id])))\n",
    "    indices = all_indices - indices_to_exclude\n",
    "    indices = sorted(list(indices))\n",
    "\n",
    "    assert in_time_stamp is not None or len(indices) > 0, '#indices:%d, problem_id:%s, user_id:%s' % (len(indices), problem_id, user_id_to_exclude)\n",
    "    return correct_program_embeddings[problem_id][indices], correct_program_id_map[problem_id][indices]\n",
    "\n",
    "def get_correct_embeddings_using_clustering(problem_id, user_id_to_exclude, inc_embedding):\n",
    "    global _user_indices, correct_program_embeddings, cluster_store\n",
    "    kmeans, kmeans_labels, kmeans_labels_to_index_map = cluster_store[problem_id][0], cluster_store[problem_id][1], cluster_store[problem_id][3]\n",
    "    X = inc_embedding\n",
    "    emb_shape = np.shape(X)\n",
    "    X = np.reshape(X, (emb_shape[0], emb_shape[1] * emb_shape[2] * emb_shape[3]))\n",
    "    cluster_index = kmeans.predict(X)[0]\n",
    "    \n",
    "    return_indices = kmeans_labels_to_index_map[cluster_index]\n",
    "    \n",
    "    if user_id_to_exclude is None:\n",
    "        indices_to_exclude = set()\n",
    "    else:\n",
    "        if user_id_to_exclude in _user_indices[problem_id]:\n",
    "            indices_to_exclude = _user_indices[problem_id][user_id_to_exclude]\n",
    "        else:\n",
    "            indices_to_exclude = set()\n",
    "    return_indices = return_indices - indices_to_exclude\n",
    "    indices = sorted(list(return_indices))\n",
    "    return correct_program_embeddings[problem_id][indices], correct_program_id_map[problem_id][indices]\n",
    "\n",
    "def get_program_details(program_id):\n",
    "    query = '''SELECT problem_id, user_id, program \n",
    "                FROM orgsource o INNER JOIN programs p ON o.program_id=p.program_id\n",
    "                WHERE o.program_id=?;'''\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        c = conn.cursor()\n",
    "        for row in c.execute(query, (program_id,)):\n",
    "            problem_id, user_id, program = row\n",
    "    return problem_id, user_id, program.encode('utf-8','ignore')\n",
    "\n",
    "def remove_empty_lines(program):\n",
    "    lines = [line for line in program.split('\\n') if len(line.strip()) > 0]\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "def get_least_k(arr, k):\n",
    "    safe_k = min(len(arr)-1, k)\n",
    "    least_k_indices = np.argpartition(arr, safe_k)[:k]\n",
    "    sorted_least_k_indices = least_k_indices[np.argsort(arr[least_k_indices])]\n",
    "    return sorted_least_k_indices, arr[sorted_least_k_indices]\n",
    "\n",
    "global_ref_program_detail_cache = {}\n",
    "def get_ref_program(program_id):\n",
    "    if program_id not in global_ref_program_detail_cache:\n",
    "        global direct_eval_set\n",
    "        c_program_id, diff_out, diff_len, edit_locations = direct_eval_set[program_id]\n",
    "\n",
    "        query='''SELECT program, user_id, subtree_list_ast_without_leaves FROM\n",
    "            programs p INNER JOIN orgsource o ON o.program_id = p.program_id\n",
    "            WHERE p.program_id=?;'''\n",
    "\n",
    "        with sqlite3.connect(db_path) as conn:\n",
    "            c = conn.cursor()\n",
    "\n",
    "            row = c.execute(query, (program_id,)).next()\n",
    "            inc_program, inc_user_id, inc_subtree_list_ast = row\n",
    "            inc_program = inc_program.encode('utf-8','ignore')\n",
    "            inc_subtree_list_ast = json.loads(inc_subtree_list_ast)\n",
    "\n",
    "            row = c.execute(query, (c_program_id,)).next()\n",
    "            ref_program, ref_user_id, ref_subtree_list_ast = row\n",
    "            ref_program = ref_program.encode('utf-8','ignore')\n",
    "            ref_subtree_list_ast = json.loads(ref_subtree_list_ast)\n",
    "\n",
    "            c.close()\n",
    "            global_ref_program_detail_cache[program_id] = (inc_program, inc_user_id, inc_subtree_list_ast, c_program_id,                                                     ref_program, ref_user_id, ref_subtree_list_ast, diff_out,                                                     edit_locations)\n",
    "    \n",
    "    return global_ref_program_detail_cache[program_id]\n",
    "\n",
    "\n",
    "def get_baselines(incorrect_embedding, correct_embeddings, correct_embedding_ids, k=25):\n",
    "    emb_shape = np.shape(incorrect_embedding)\n",
    "    flat_len = emb_shape[1] * emb_shape[2] * emb_shape[3]\n",
    "    incorrect_embedding = np.reshape(incorrect_embedding, (1, flat_len))\n",
    "    correct_embeddings = np.reshape(correct_embeddings, (np.shape(correct_embeddings)[0], flat_len))\n",
    "\n",
    "    cosine_distances = cdist(incorrect_embedding, correct_embeddings, 'cosine')\n",
    "    indices, vals = get_least_k(cosine_distances[0], k)\n",
    "    k = min(k, len(correct_embeddings))\n",
    "    baselines = correct_embeddings[indices[:k]]\n",
    "    baseline_ids = correct_embedding_ids[indices[:k]]\n",
    "    emb_shape = list(emb_shape)\n",
    "    emb_shape[0] = k\n",
    "    baselines = np.reshape(baselines, emb_shape)\n",
    "    return baselines, baseline_ids\n",
    "\n",
    "def get_verified_baseline(baselines, baseline_ids, problem_id, test_id):\n",
    "    global predictions_and_gradients\n",
    "    dummy_program_vec = [0]\n",
    "    for idx in range(len(baselines)):\n",
    "        baseline = baselines[idx:idx+1]\n",
    "        baseline_id = baseline_ids[idx]\n",
    "        example_x = [ np.array([dummy_program_vec]), np.array([[problem_id]]), np.array([[test_id]]) ]\n",
    "        top_label_id, score = top_label_id_and_score(baseline, example_x, predictions_and_gradients)\n",
    "        correct_prediction = np.equal(top_label_id, 1)\n",
    "        if correct_prediction:\n",
    "            return baseline, baseline_id, idx\n",
    "    return None, None, None\n",
    "\n",
    "def get_line_attribution(subtree_attributions, program_id):\n",
    "    global subtree_to_line_maps\n",
    "    subtree_to_line = subtree_to_line_maps[program_id]\n",
    "    line_attributions = {}\n",
    "    for idx, attrb in enumerate(subtree_attributions):\n",
    "        try:\n",
    "            line = subtree_to_line[idx]\n",
    "        except:\n",
    "            break\n",
    "        if line not in line_attributions:\n",
    "            line_attributions[line] = []\n",
    "        line_attributions[line].append(attrb)\n",
    "    lines = list(sorted(line_attributions.keys()))\n",
    "    min_line = lines[0]\n",
    "    line_attributions_list = []\n",
    "    for line in lines:\n",
    "        line_attributions_list.append(np.mean(line_attributions[line]))\n",
    "    return np.array(line_attributions_list), min_line\n",
    "\n",
    "def get_top_k_lines(subtree_attributions, program_id, k):\n",
    "    line_attributions_list, min_line = get_line_attribution(subtree_attributions, program_id)\n",
    "    k = min(len(line_attributions_list), k)\n",
    "    indices, attrbs = get_top_k(line_attributions_list, k)\n",
    "    lines = map(lambda index : index + min_line, indices)\n",
    "    return lines, attrbs, len(line_attributions_list)\n",
    "\n",
    "def get_top_k(arr, k):\n",
    "    top_k_indices = np.argpartition(arr, -k)[-k:]\n",
    "    top_k_indices = list(reversed(top_k_indices[np.argsort(arr[top_k_indices])]))\n",
    "    return top_k_indices, arr[top_k_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_directory = 'data/network_inputs/bugloc-original/'\n",
    "checkpoints_directory = 'data/checkpoints/bugloc-original/'\n",
    "db_path = 'data/dataset.db'\n",
    "dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class custom_args:    \n",
    "    def __init__(self, data_directory, checkpoints_directory, batch_size=32, embedding_dim=32, dropout=0.2, epochs=50, only_test=False):\n",
    "        self.data_directory = data_directory\n",
    "        self.checkpoints_directory = checkpoints_directory\n",
    "        self.batch_size = 16\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.dropout = dropout\n",
    "        self.epochs = epochs\n",
    "        self.only_test = only_test\n",
    "        \n",
    "args = custom_args(data_directory, checkpoints_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data\n",
    "data_directory = args.data_directory\n",
    "checkpoints_directory = args.checkpoints_directory\n",
    "batch_size = args.batch_size\n",
    "embedding_dim = args.embedding_dim\n",
    "\n",
    "if dataset is None:\n",
    "    dataset = Dataset(data_directory)\n",
    "tl_dict = dataset.get_tl_dict()\n",
    "rev_tl_dict = dataset.get_rev_tl_dict()\n",
    "rev_problem_id_dict = get_rev_dict(dataset.get_problem_id_dict())\n",
    "rev_test_dict = get_rev_dict(dataset.get_test_dict())\n",
    "\n",
    "num_train, num_validation, num_test, num_all = dataset.data_size\n",
    "print 'Training:', num_train, '\\nValidation:', num_validation, '\\nTest:', num_test, '\\nAll:', num_all\n",
    "print 'vocabulary size:', dataset.vocab_size\n",
    "\n",
    "vocab_size = dataset.vocab_size\n",
    "cnt_problem_ids = dataset.cnt_problem_IDs\n",
    "test_suite_size = dataset.test_suite_size\n",
    "max_subtrees = dataset.max_subtrees_per_program\n",
    "max_nodes = dataset.max_nodes_per_subtree\n",
    "\n",
    "print 'cnt_problem_ids:', cnt_problem_ids, 'test_suite_size:', test_suite_size\n",
    "print 'max_subtrees:', max_subtrees, 'max_nodes:', max_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "programs, program_lengths, subtree_lengths, problem_ids, test_ids, verdicts, buggy_subtrees, program_ids = dataset.get_batch(start=0, end=num_all, which='all')\n",
    "\n",
    "train_x = [programs[:num_train], np.array(problem_ids[:num_train]), np.array(test_ids[:num_train])]\n",
    "train_y = keras.utils.to_categorical(verdicts[:num_train], num_classes=2)\n",
    "\n",
    "valid_x = [programs[num_train:num_train+num_validation], np.array(problem_ids[num_train:num_train+num_validation]), np.array(test_ids[num_train:num_train+num_validation])]\n",
    "valid_y = keras.utils.to_categorical(verdicts[num_train:num_train+num_validation], num_classes=2)\n",
    "\n",
    "otest_x = [programs[num_train+num_validation:], np.array(problem_ids[num_train+num_validation:]), np.array(test_ids[num_train+num_validation:])]\n",
    "otest_y = keras.utils.to_categorical(verdicts[num_train+num_validation:], num_classes=2)\n",
    "\n",
    "print '#train:', len(train_y), '#valid:', len(valid_y), '#test:', len(otest_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_program_ids = set(program_ids[num_train+num_validation:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = np.load('data/eval_set.npy').item()\n",
    "print '#problems:', len(eval_set),\n",
    "\n",
    "direct_eval_set = {}\n",
    "for problem_id in eval_set:\n",
    "    for program_id, row in eval_set[problem_id].items():\n",
    "        direct_eval_set[program_id] = row\n",
    "\n",
    "eval_set_program_ids = direct_eval_set.keys()\n",
    "print '#programs:', len(eval_set_program_ids)\n",
    "\n",
    "subtree_to_line_maps = np.load('data/subtree_to_line_map.npy').item()\n",
    "print 'len(subtree_to_line_maps):', len(subtree_to_line_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errs_in_finding_buggy_subtrees = set(np.load(os.path.join(args.data_directory, 'errs_in_finding_buggy_subtrees.npy')))\n",
    "print len(errs_in_finding_buggy_subtrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First load original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find checkpoint\n",
    "ckpts = glob.glob(os.path.join(checkpoints_directory, \"weights.*-*.hdf5\"))\n",
    "best_checkpoint, initial_epoch = None, 0\n",
    "if len(ckpts) > 0:\n",
    "    for ckpt in ckpts:\n",
    "        # ckpt_epoch = int(ckpt.split('-')[0].split('.')[1])\n",
    "        ckpt_epoch = int(ckpt.split('/')[-1].split('-')[0].split('.')[1])\n",
    "        if initial_epoch < ckpt_epoch:\n",
    "            initial_epoch = ckpt_epoch\n",
    "            best_checkpoint = ckpt\n",
    "            \n",
    "print best_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_model = get_org_model(max_subtrees, max_nodes, embedding_dim, vocab_size, best_checkpoint)\n",
    "print 'evaluating org model'\n",
    "print 'valid'\n",
    "print org_model.evaluate(valid_x, valid_y, verbose=1)\n",
    "\n",
    "print '\\ntest'\n",
    "print org_model.evaluate(otest_x, otest_y, verbose=1)\n",
    "\n",
    "print '\\ntrain'\n",
    "train_eval_cnt = 14337\n",
    "small_train_x = [train_x[0][:train_eval_cnt], train_x[1][:train_eval_cnt], train_x[2][:train_eval_cnt]]\n",
    "print org_model.evaluate(small_train_x, train_y[:train_eval_cnt], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break model in two parts -\n",
    "### 1) Given program, get embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "emb_model = get_emb_model(max_subtrees, max_nodes, embedding_dim, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## use org model to initialize emb_model weights correctly\n",
    "emb_model.layers[1].set_weights([org_model.get_weights()[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Given program embedding as input, do rest of the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = get_rest_of_the_model(max_subtrees, max_nodes, embedding_dim, vocab_size)\n",
    "model_updated_for_attribution = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## use org model to initialize emb_model weights correctly\n",
    "weights_list = org_model.get_weights()   # 1st correspond to embedding layer, which needs to be removed\n",
    "model.set_weights(weights_list[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather failing test case examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neg_program_ids, neg_programs, neg_problem_ids, neg_test_ids,  neg_verdicts, neg_buggy_subtrees, \\\n",
    "neg_buggy_line_to_subtrees = prepare_failing_data(data_directory, eval_program_ids-errs_in_finding_buggy_subtrees)\n",
    "\n",
    "evaluation_dataset = (neg_program_ids, neg_programs, neg_problem_ids, neg_test_ids, neg_verdicts, neg_buggy_subtrees, neg_buggy_line_to_subtrees)\n",
    "evaluation_dataset_length = len(neg_program_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "org_model_Y_pred, model_Y_pred = [], []\n",
    "test_cnt = len(neg_verdicts)\n",
    "for idx in range(test_cnt):\n",
    "    neg_program_id = neg_program_ids[idx]\n",
    "    neg_program = neg_programs[idx]\n",
    "    neg_problem_id = neg_problem_ids[idx]\n",
    "    neg_test_id = neg_test_ids[idx]\n",
    "    neg_verdict = neg_verdicts[idx]\n",
    "    neg_buggy_subtree = neg_buggy_subtrees[idx]\n",
    "\n",
    "    example_x = [ np.array([neg_program]), np.array([[neg_problem_id]]), np.array([[neg_test_id]]) ]\n",
    "    example_y = keras.utils.to_categorical([neg_verdict], num_classes=2)\n",
    "\n",
    "    emb_program = emb_model.predict([example_x[0]])\n",
    "    test_x = [emb_program, example_x[1], example_x[2]]\n",
    "    test_y = example_y\n",
    "   \n",
    "    model_Y_pred.append(np.squeeze(model.predict(test_x, verbose=False)))\n",
    "    org_model_Y_pred.append(np.squeeze(org_model.predict(example_x, verbose=False)))\n",
    "\n",
    "print 'new model results:'\n",
    "model_Y_pred = np.argmax(model_Y_pred, axis=1)\n",
    "print '#correct predictions:', np.sum(neg_verdicts[:test_cnt] == model_Y_pred)\n",
    "print(classification_report(neg_verdicts[:test_cnt], model_Y_pred))\n",
    "\n",
    "print '\\norg model results:'\n",
    "org_model_Y_pred = np.argmax(org_model_Y_pred, axis=1)\n",
    "print '#correct predictions:', np.sum(neg_verdicts[:test_cnt] == org_model_Y_pred)\n",
    "print(classification_report(neg_verdicts[:test_cnt], org_model_Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update model for attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not model_updated_for_attribution:\n",
    "    target_label_one_hot = K.placeholder(shape=(None,2,))\n",
    "    softmax_output = model.layers[-1].output\n",
    "    label_softmax_output = K.sum(softmax_output * target_label_one_hot)\n",
    "    program_embedding_input = model.input[0]\n",
    "    label_gradients = K.gradients(label_softmax_output, program_embedding_input)[0]\n",
    "    model_updated_for_attribution = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "print sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_and_gradients = make_predictions_and_gradients(sess, model, softmax_output, label_gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather all correct programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='''SELECT p.program_id, program, user_id, subtree_list_ast_without_leaves, time_stamp FROM\n",
    "        programs p INNER JOIN orgsource o ON o.program_id = p.program_id\n",
    "        INNER JOIN test_run_summary trs ON trs.program_id = p.program_id\n",
    "        WHERE trs.verdict=\"ALL_PASS\" AND problem_id=?;'''\n",
    "\n",
    "correct_programs = {}\n",
    "\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    problem_ids_used = [str(row[0]) for row in c.execute('SELECT DISTINCT problem_id FROM orgsource;')]\n",
    "\n",
    "    for problem_id in problem_ids_used:\n",
    "        correct_programs[problem_id] = []\n",
    "        vectorization_errors = 0\n",
    "        size_mismatch_errors = 0\n",
    "\n",
    "        for row in c.execute(query, (problem_id,)):\n",
    "            program_id, program, user_id, subtree_list_ast, time_stamp = row\n",
    "            subtree_list_ast = json.loads(subtree_list_ast)\n",
    "            program = program.encode('utf-8','ignore')\n",
    "\n",
    "            id_map = get_id_map(subtree_list_ast, program_id=program_id)\n",
    "            norm_id_subtree_list_ast = normalize_ids(subtree_list_ast, id_map)\n",
    "            try:\n",
    "                vec_ast, buggy_subtree = vectorize_subtree_list_ast(tl_dict, norm_id_subtree_list_ast, dataset.max_subtrees_per_program, dataset.max_nodes_per_subtree, buggy_line=0)\n",
    "            except KeyError:\n",
    "                vectorization_errors += 1\n",
    "            \n",
    "            if vec_ast is not None:\n",
    "                correct_programs[problem_id].append((program_id, program, user_id, time_stamp, id_map, vec_ast))\n",
    "            else:\n",
    "                size_mismatch_errors += 1\n",
    "\n",
    "        print 'problem_id:', problem_id, '#correct_programs:', len(correct_programs[problem_id]),\n",
    "        print 'vectorization_errors:', vectorization_errors, 'size_mismatch_errors:', size_mismatch_errors\n",
    "\n",
    "    c.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get embeddings corresponding to correct programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correct_program_embeddings = {}\n",
    "correct_program_id_map = {}\n",
    "_user_indices = {}\n",
    "for problem_id in correct_programs:\n",
    "    _user_indices[problem_id] = {}\n",
    "    correct_program_id_map[problem_id] = []\n",
    "    ast_list = []\n",
    "    for idx, (program_id, program, user_id, time_stamp, id_map, vec_ast) in enumerate(correct_programs[problem_id]):\n",
    "        ast_list.append(vec_ast)\n",
    "        correct_program_id_map[problem_id].append(program_id)\n",
    "        if user_id not in _user_indices[problem_id]:\n",
    "            _user_indices[problem_id][user_id] = set()\n",
    "        _user_indices[problem_id][user_id].add(idx)\n",
    "        \n",
    "    ast_batch, _, _ = dataset.prepare_batch(ast_list)\n",
    "    embeddings_batch = get_embedded_program(sess, emb_model, ast_batch, None)\n",
    "    correct_program_embeddings[problem_id] = embeddings_batch\n",
    "    correct_program_id_map[problem_id] = np.array(correct_program_id_map[problem_id])\n",
    "    print problem_id, len(correct_program_embeddings[problem_id]), len(_user_indices[problem_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bug-localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_to_line_map = np.load('data/bug_to_line_map.npy').item()\n",
    "print 'len(bug_to_line_map):', len(bug_to_line_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eval_programs = set()\n",
    "for idx in range(len(neg_program_ids)):\n",
    "    neg_program_id = neg_program_ids[idx]\n",
    "    all_eval_programs.add(neg_program_id)\n",
    "print len(all_eval_programs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_predictions = []\n",
    "empty_baselines = []\n",
    "\n",
    "all_faulty_lines = {}\n",
    "faulty_lines_found = {10:{}, 5:{}, 1:{}}\n",
    "\n",
    "pairs_localized = {10:set(), 5:set(), 1:set()}\n",
    "pairs_missed = {10:set(), 5:set(), 1:set()}\n",
    "programs_localized = {10:set(), 5:set(), 1:set()}\n",
    "all_eval_programs = set()\n",
    "remaining_eval_programs = set()\n",
    "max_k = 10\n",
    "\n",
    "baseline_indices = []\n",
    "\n",
    "todo_cnt = len(neg_program_ids)\n",
    "done = 0\n",
    "skipped = []\n",
    "\n",
    "for idx in range(todo_cnt):\n",
    "    neg_program_id = neg_program_ids[idx]\n",
    "    neg_program = neg_programs[idx]\n",
    "    neg_problem_id = neg_problem_ids[idx]\n",
    "    neg_test_id = neg_test_ids[idx]\n",
    "    neg_verdict = neg_verdicts[idx]\n",
    "    neg_buggy_subtree = neg_buggy_subtrees[idx]\n",
    "    neg_buggy_line_to_subtree = neg_buggy_line_to_subtrees[idx]\n",
    "\n",
    "    if neg_program_id not in all_faulty_lines:\n",
    "        all_faulty_lines[neg_program_id] = {}\n",
    "    \n",
    "    if neg_program_id in bug_to_line_map:\n",
    "        try:\n",
    "            all_faulty_lines[neg_program_id][neg_test_id] = deepcopy(bug_to_line_map[neg_program_id][rev_test_dict[neg_test_id]])\n",
    "        except KeyError:\n",
    "            skipped.append((neg_program_id, rev_problem_id_dict[neg_problem_id], rev_test_dict[neg_test_id]))\n",
    "            print '#Skipped:', len(skipped), '\\r',\n",
    "            continue\n",
    "    else:\n",
    "        all_faulty_lines[neg_program_id][neg_test_id] = set(neg_buggy_line_to_subtree.keys())\n",
    "        \n",
    "    all_eval_programs.add(neg_program_id)\n",
    "        \n",
    "    for each in [10,5,1]:\n",
    "        if neg_program_id not in faulty_lines_found[each]:\n",
    "            faulty_lines_found[each][neg_program_id] = {neg_test_id:set()}\n",
    "        else:\n",
    "            assert neg_test_id not in faulty_lines_found[each][neg_program_id]\n",
    "            faulty_lines_found[each][neg_program_id][neg_test_id] = set()\n",
    "    \n",
    "    assert len(all_faulty_lines[neg_program_id][neg_test_id])>0, neg_program_id\n",
    "        \n",
    "\n",
    "    example_x = [ np.array([neg_program]), np.array([[neg_problem_id]]), np.array([[neg_test_id]]) ]\n",
    "    example_y = keras.utils.to_categorical([neg_verdict], num_classes=2)\n",
    "    \n",
    "    emb_inc_program = get_embedded_program(sess, emb_model, example_x[0], neg_program_id)\n",
    "\n",
    "    top_label_id, score = top_label_id_and_score(emb_inc_program, example_x, predictions_and_gradients)\n",
    "    correct_neg_prediction = np.equal(top_label_id, neg_verdict)\n",
    "\n",
    "    if not correct_neg_prediction:\n",
    "        wrong_predictions.append((neg_program_id,neg_test_id))\n",
    "        continue\n",
    "    else:\n",
    "        remaining_eval_programs.add(neg_program_id)\n",
    "    \n",
    "    user_id_to_exclude = get_ref_program(neg_program_id)[1]\n",
    "    emb_corr_programs, emb_corr_program_ids = get_correct_embeddings(rev_problem_id_dict[neg_problem_id], user_id_to_exclude)\n",
    "    baselines, baseline_ids = get_baselines(emb_inc_program, emb_corr_programs, emb_corr_program_ids, k=25)\n",
    "    v_baseline, v_baseline_id, v_baseline_index = get_verified_baseline(baselines, baseline_ids, neg_problem_id, neg_test_id)\n",
    "    baseline_indices.append(v_baseline_index)\n",
    "    \n",
    "    if v_baseline is None:\n",
    "        empty_baselines.append((neg_program_id,neg_test_id))\n",
    "        continue\n",
    "\n",
    "    baseline_emb = top_baseline = v_baseline\n",
    "    \n",
    "    attributions, predictions = integrated_gradients(emb_inc_program, example_x, example_y, predictions_and_gradients, baseline_emb, steps=100)\n",
    "    subtree_attributions = np.squeeze(np.mean(np.amax(attributions, axis=-1), axis=-1))  # np.squeeze()\n",
    "    top_k_subtrees, top_k_subtree_vals = get_top_k(subtree_attributions, max_k)\n",
    "\n",
    "    top_k_lines, top_k_line_vals, program_length = get_top_k_lines(subtree_attributions, neg_program_id, k=max_k)\n",
    "    \n",
    "    for top_k in [10,5,1]:\n",
    "        some_line_found = False\n",
    "        for line in all_faulty_lines[neg_program_id][neg_test_id]:\n",
    "            if line in top_k_lines[:top_k]:\n",
    "                faulty_lines_found[top_k][neg_program_id][neg_test_id].add(line)\n",
    "                some_line_found = True\n",
    "                           \n",
    "        if some_line_found:\n",
    "            pairs_localized[top_k].add((neg_program_id,neg_test_id))\n",
    "            programs_localized[top_k].add((neg_program_id))\n",
    "        else:\n",
    "            pairs_missed[top_k].add((neg_program_id,neg_test_id))\n",
    "        \n",
    "\n",
    "    remaining = todo_cnt - idx - 1\n",
    "    denom = idx+1\n",
    "    \n",
    "    if idx%5==0 and idx>0:\n",
    "        for top_k in [10,5,1]:\n",
    "            print '%d|F:%4d, M:%4d, A:%5.2f%%' % (top_k, len(pairs_localized[top_k]), len(pairs_missed[top_k]), 100.0*len(pairs_localized[top_k])/denom),\n",
    "        print '|| CNT:%4d, WP:%3d, EB:%3d \\r' % (remaining, len(wrong_predictions), len(empty_baselines)),\n",
    "        \n",
    "    done += 1\n",
    "        \n",
    "for top_k in [10,5,1]:\n",
    "    print '%d|F:%4d, M:%4d, A:%5.2f%%' % (top_k, len(pairs_localized[top_k]), len(pairs_missed[top_k]), 100.0*len(pairs_localized[top_k])/denom),\n",
    "print '|| CNT:%4d, WP:%3d, EB:%3d \\r' % (remaining, len(wrong_predictions), len(empty_baselines))\n",
    "\n",
    "print 'skipped:', len(skipped), '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pairs = sum(map(len, [pairs_localized[top_k], pairs_missed[top_k], wrong_predictions]))\n",
    "print 'total_pairs:', total_pairs, 'pairs localized:'\n",
    "print 'top_k localized'\n",
    "for top_k in [10,5,1]:\n",
    "    print top_k, len(pairs_localized[top_k]), '%4.2f%%' % (100.0*len(pairs_localized[top_k])/total_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_faulty_lines = {}\n",
    "for program_id in all_faulty_lines:\n",
    "    if program_id not in prog_faulty_lines: prog_faulty_lines[program_id] = set()\n",
    "    for test_id in all_faulty_lines[program_id]:\n",
    "        prog_faulty_lines[program_id].update(all_faulty_lines[program_id][test_id])\n",
    "        \n",
    "cnt_faulty_lines = 0\n",
    "for program_id in prog_faulty_lines:\n",
    "    cnt_faulty_lines += len(prog_faulty_lines[program_id])\n",
    "\n",
    "prog_faulty_lines_found = {10:{},5:{},1:{}}\n",
    "# print cnt_faulty_lines,\n",
    "for top_k in [10,5,1]:\n",
    "    for program_id in faulty_lines_found[top_k]:\n",
    "        if program_id not in prog_faulty_lines_found[top_k]: prog_faulty_lines_found[top_k][program_id] = set()\n",
    "        for test_id in faulty_lines_found[top_k][program_id]:\n",
    "            prog_faulty_lines_found[top_k][program_id].update(faulty_lines_found[top_k][program_id][test_id])\n",
    "    \n",
    "    cnt_lines_found = 0\n",
    "    for program_id in prog_faulty_lines_found[top_k]:\n",
    "        cnt_lines_found += len(prog_faulty_lines_found[top_k][program_id])\n",
    "\n",
    "#     print cnt_lines_found, '%4.2f%%' % (100.0*cnt_lines_found/cnt_faulty_lines),\n",
    "# print '\\n'\n",
    "\n",
    "# for programs with more than 1 faulty lines\n",
    "print 'Grouped by line diff counts:'\n",
    "cnt_faulty_progs, cnt_faulty_progs_found = {}, {}\n",
    "cnt_faulty_lines, cnt_lines_found = {}, {}\n",
    "for top_k in [10,5,1]:\n",
    "    cnt_faulty_progs[top_k], cnt_faulty_progs_found[top_k] = {'total':0}, {'total':0}\n",
    "    cnt_faulty_lines[top_k], cnt_lines_found[top_k] = {'total':0}, {'total':0}\n",
    "    for num_buggy_lines in range(1,6):\n",
    "        cnt_faulty_progs[top_k][num_buggy_lines], cnt_faulty_progs_found[top_k][num_buggy_lines] = 0, 0\n",
    "        cnt_faulty_lines[top_k][num_buggy_lines], cnt_lines_found[top_k][num_buggy_lines] = 0, 0\n",
    "        for program_id in prog_faulty_lines:\n",
    "            if len(prog_faulty_lines[program_id]) == num_buggy_lines:\n",
    "                cnt_faulty_progs[top_k][num_buggy_lines] += 1\n",
    "                cnt_faulty_lines[top_k][num_buggy_lines] += num_buggy_lines\n",
    "                cnt_faulty_progs[top_k]['total'] += 1\n",
    "                cnt_faulty_lines[top_k]['total'] += num_buggy_lines\n",
    "                \n",
    "                cnt_faulty_progs_found[top_k][num_buggy_lines] += 1 if len(prog_faulty_lines_found[top_k][program_id]) > 0 else 0\n",
    "                cnt_lines_found[top_k][num_buggy_lines] += len(prog_faulty_lines_found[top_k][program_id])\n",
    "                cnt_faulty_progs_found[top_k]['total'] += 1 if len(prog_faulty_lines_found[top_k][program_id]) > 0 else 0\n",
    "                cnt_lines_found[top_k]['total'] += len(prog_faulty_lines_found[top_k][program_id])\n",
    "\n",
    "print '\\t\\t\\t\\t top-10 \\t\\t top-5 \\t\\t top-1'\n",
    "print 'diff|progs lines|', '%-22s|' % ('#10 PF \\t #10 LF'), '%-22s|' % ('#5 PF \\t #5 LF'), '%-22s|' % ('#1 PF \\t #1 LF') \n",
    "\n",
    "for key in cnt_faulty_lines[10]:    \n",
    "    if cnt_faulty_progs[10][key] == 0:\n",
    "        continue\n",
    "    print '{}\\t'.format(key), '%4d %4d' % (cnt_faulty_progs[10][key], cnt_faulty_lines[10][key]),\n",
    "    for top_k in [10,5,1]:\n",
    "        print '%4d (%6.2f%%)' % (cnt_faulty_progs_found[top_k][key], (100.0*cnt_faulty_progs_found[top_k][key]/cnt_faulty_progs[top_k][key])),\n",
    "        print '%4d (%6.2f%%)' % (cnt_lines_found[top_k][key], (100.0*cnt_lines_found[top_k][key]/cnt_faulty_lines[top_k][key]) ),\n",
    "    print\n",
    "\n",
    "print\n",
    "\n",
    "baseline_indices = list(sorted(baseline_indices))\n",
    "for percentile in [50,60,70,80,90,95,98,99]:\n",
    "    i = int( percentile * len(baseline_indices) / 100.0 )\n",
    "    print 'percentile:', percentile, 'baseline_indices:',  baseline_indices[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### results with wrong baselines counted explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pairs = sum(map(len, [pairs_localized[top_k], pairs_missed[top_k]]))\n",
    "print 'total_pairs', 10, 5, 1\n",
    "print total_pairs,\n",
    "for top_k in [10,5,1]:\n",
    "    # print top_k, tests_localized[top_k], tests_localized[top_k] + tests_missed[top_k] + len(skipped) + wrong_predictions\n",
    "    print len(pairs_localized[top_k]), '%4.2f%%' % (100.0*len(pairs_localized[top_k])/total_pairs),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_faulty_lines = {}\n",
    "for program_id in all_faulty_lines:\n",
    "    if program_id not in prog_faulty_lines: prog_faulty_lines[program_id] = set()\n",
    "    for test_id in all_faulty_lines[program_id]:\n",
    "        if (program_id, test_id) not in wrong_predictions:\n",
    "            prog_faulty_lines[program_id].update(all_faulty_lines[program_id][test_id])\n",
    "        \n",
    "cnt_faulty_lines = 0\n",
    "for program_id in prog_faulty_lines:\n",
    "    cnt_faulty_lines += len(prog_faulty_lines[program_id])\n",
    "\n",
    "prog_faulty_lines_found = {10:{},5:{},1:{}}\n",
    "# print 'total top-10 top-5 top-1'\n",
    "# print cnt_faulty_lines,\n",
    "for top_k in [10,5,1]:\n",
    "    for program_id in faulty_lines_found[top_k]:\n",
    "        if program_id not in prog_faulty_lines_found[top_k]: prog_faulty_lines_found[top_k][program_id] = set()\n",
    "        for test_id in faulty_lines_found[top_k][program_id]:\n",
    "            prog_faulty_lines_found[top_k][program_id].update(faulty_lines_found[top_k][program_id][test_id])\n",
    "    \n",
    "    cnt_lines_found = 0\n",
    "    for program_id in prog_faulty_lines_found[top_k]:\n",
    "        cnt_lines_found += len(prog_faulty_lines_found[top_k][program_id])\n",
    "\n",
    "#     print cnt_lines_found, '%5.2f%%' % (100.0*cnt_lines_found/cnt_faulty_lines),\n",
    "# print '\\n'\n",
    "\n",
    "\n",
    "print 'Grouped by line diff counts:'\n",
    "cnt_faulty_progs, cnt_faulty_progs_found = {}, {}\n",
    "cnt_faulty_lines, cnt_lines_found = {}, {}\n",
    "for top_k in [10,5,1]:\n",
    "    cnt_faulty_progs[top_k], cnt_faulty_progs_found[top_k] = {'total':0}, {'total':0}\n",
    "    cnt_faulty_lines[top_k], cnt_lines_found[top_k] = {'total':0}, {'total':0}\n",
    "    for num_buggy_lines in range(1,6):\n",
    "        cnt_faulty_progs[top_k][num_buggy_lines], cnt_faulty_progs_found[top_k][num_buggy_lines] = 0, 0\n",
    "        cnt_faulty_lines[top_k][num_buggy_lines], cnt_lines_found[top_k][num_buggy_lines] = 0, 0\n",
    "        for program_id in prog_faulty_lines:\n",
    "            if len(prog_faulty_lines[program_id]) == num_buggy_lines:\n",
    "                cnt_faulty_progs[top_k][num_buggy_lines] += 1\n",
    "                cnt_faulty_lines[top_k][num_buggy_lines] += num_buggy_lines\n",
    "                cnt_faulty_progs[top_k]['total'] += 1\n",
    "                cnt_faulty_lines[top_k]['total'] += num_buggy_lines\n",
    "                \n",
    "                cnt_faulty_progs_found[top_k][num_buggy_lines] += 1 if len(prog_faulty_lines_found[top_k][program_id]) > 0 else 0\n",
    "                cnt_lines_found[top_k][num_buggy_lines] += len(prog_faulty_lines_found[top_k][program_id])\n",
    "                cnt_faulty_progs_found[top_k]['total'] += 1 if len(prog_faulty_lines_found[top_k][program_id]) > 0 else 0\n",
    "                cnt_lines_found[top_k]['total'] += len(prog_faulty_lines_found[top_k][program_id])\n",
    "\n",
    "print '\\t\\t\\t\\t top-10 \\t\\t top-5 \\t\\t top-1'\n",
    "print 'diff|progs lines|', '%-22s|' % ('#10 PF \\t #10 LF'), '%-22s|' % ('#5 PF \\t #5 LF'), '%-22s|' % ('#1 PF \\t #1 LF') \n",
    "\n",
    "for key in cnt_faulty_lines[10]:    \n",
    "    if cnt_faulty_progs[10][key] == 0:\n",
    "        continue\n",
    "    print '{}\\t'.format(key), '%4d %4d' % (cnt_faulty_progs[10][key], cnt_faulty_lines[10][key]),\n",
    "    for top_k in [10,5,1]:\n",
    "        print '%4d (%6.2f%%)' % (cnt_faulty_progs_found[top_k][key], (100.0*cnt_faulty_progs_found[top_k][key]/cnt_faulty_progs[top_k][key])),\n",
    "        print '%4d (%6.2f%%)' % (cnt_lines_found[top_k][key], (100.0*cnt_lines_found[top_k][key]/cnt_faulty_lines[top_k][key]) ),\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store programs with correct prediction for comparison with baseline techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(wrong_predictions), len(remaining_eval_programs)\n",
    "print wrong_predictions[0], list(remaining_eval_programs)[0], type(remaining_eval_programs)\n",
    "wrong_predictions_ = map(lambda (x,y):(x,rev_test_dict[y]), wrong_predictions)\n",
    "np.save('data/TCNN_wrong_classifications', wrong_predictions_)\n",
    "np.save('data/TCNN_correct_classifications', remaining_eval_programs)\n",
    "np.save('data/test_wise_faulty_lines', all_faulty_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat with clustering of baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cluster correct embeddings\n",
    "no_of_clusters = 5\n",
    "cluster_store = {}\n",
    "for problem_id in correct_programs:\n",
    "    X = deepcopy(correct_program_embeddings[problem_id])\n",
    "    emb_shape = np.shape(X)\n",
    "    flat_len = emb_shape[1] * emb_shape[2] * emb_shape[3]\n",
    "    X = np.reshape(X, (emb_shape[0], flat_len))\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=no_of_clusters)\n",
    "    kmeans.fit(X)\n",
    "    kmeans_labels = kmeans.labels_\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    kmeans_labels_to_index_map = {}\n",
    "    for idx in range(len(kmeans_labels)):\n",
    "        if kmeans_labels[idx] not in kmeans_labels_to_index_map:\n",
    "            kmeans_labels_to_index_map[kmeans_labels[idx]] = set()\n",
    "        kmeans_labels_to_index_map[kmeans_labels[idx]].add(idx)\n",
    "    cluster_store[problem_id] = [kmeans, kmeans_labels, cluster_centers, kmeans_labels_to_index_map]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_wrong_predictions = []\n",
    "c_empty_baselines = []\n",
    "\n",
    "c_all_faulty_lines = {}\n",
    "c_faulty_lines_found = {10:{}, 5:{}, 1:{}}\n",
    "\n",
    "c_pairs_localized = {10:set(), 5:set(), 1:set()}\n",
    "c_pairs_missed = {10:set(), 5:set(), 1:set()}\n",
    "c_programs_localized = {10:set(), 5:set(), 1:set()}\n",
    "c_all_eval_programs = set()\n",
    "max_k = 10\n",
    "\n",
    "c_baseline_indices = []\n",
    "\n",
    "c_todo_cnt = len(neg_program_ids)\n",
    "c_done = 0\n",
    "c_skipped = []\n",
    "\n",
    "for idx in range(c_todo_cnt):\n",
    "    neg_program_id = neg_program_ids[idx]\n",
    "    neg_program = neg_programs[idx]\n",
    "    neg_problem_id = neg_problem_ids[idx]\n",
    "    neg_test_id = neg_test_ids[idx]\n",
    "    neg_verdict = neg_verdicts[idx]\n",
    "    neg_buggy_subtree = neg_buggy_subtrees[idx]\n",
    "    neg_buggy_line_to_subtree = neg_buggy_line_to_subtrees[idx]\n",
    "\n",
    "    if neg_program_id not in c_all_faulty_lines:\n",
    "        c_all_faulty_lines[neg_program_id] = {}\n",
    "    \n",
    "    if neg_program_id in bug_to_line_map:\n",
    "        try:\n",
    "            c_all_faulty_lines[neg_program_id][neg_test_id] = deepcopy(bug_to_line_map[neg_program_id][rev_test_dict[neg_test_id]])\n",
    "        except KeyError:\n",
    "            c_skipped.append((neg_program_id, rev_problem_id_dict[neg_problem_id], rev_test_dict[neg_test_id]))\n",
    "            print '#Skipped:', len(c_skipped), '\\r',\n",
    "            continue\n",
    "    else:\n",
    "        c_all_faulty_lines[neg_program_id][neg_test_id] = set(neg_buggy_line_to_subtree.keys())\n",
    "        \n",
    "    c_all_eval_programs.add(neg_program_id)\n",
    "        \n",
    "    for each in [10,5,1]:\n",
    "        if neg_program_id not in c_faulty_lines_found[each]:\n",
    "            c_faulty_lines_found[each][neg_program_id] = {neg_test_id:set()}\n",
    "        else:\n",
    "            assert neg_test_id not in c_faulty_lines_found[each][neg_program_id]\n",
    "            c_faulty_lines_found[each][neg_program_id][neg_test_id] = set()\n",
    "    \n",
    "    assert len(c_all_faulty_lines[neg_program_id][neg_test_id])>0, neg_program_id\n",
    "        \n",
    "\n",
    "    example_x = [ np.array([neg_program]), np.array([[neg_problem_id]]), np.array([[neg_test_id]]) ]\n",
    "    example_y = keras.utils.to_categorical([neg_verdict], num_classes=2)\n",
    "    \n",
    "    emb_inc_program = get_embedded_program(sess, emb_model, example_x[0], neg_program_id)\n",
    "\n",
    "    top_label_id, score = top_label_id_and_score(emb_inc_program, example_x, predictions_and_gradients)\n",
    "    correct_neg_prediction = np.equal(top_label_id, neg_verdict)\n",
    "\n",
    "    if not correct_neg_prediction:\n",
    "        c_wrong_predictions.append((neg_program_id,neg_test_id))\n",
    "        continue\n",
    "    \n",
    "    user_id_to_exclude = get_ref_program(neg_program_id)[1]\n",
    "    emb_corr_programs, emb_corr_program_ids = get_correct_embeddings_using_clustering(rev_problem_id_dict[neg_problem_id], user_id_to_exclude, emb_inc_program)\n",
    "    baselines, baseline_ids = get_baselines(emb_inc_program, emb_corr_programs, emb_corr_program_ids, k=25)\n",
    "    v_baseline, v_baseline_id, v_baseline_index = get_verified_baseline(baselines, baseline_ids, neg_problem_id, neg_test_id)\n",
    "    c_baseline_indices.append(v_baseline_index)\n",
    "    \n",
    "    if v_baseline is None:\n",
    "        c_empty_baselines.append((neg_program_id,neg_test_id))\n",
    "        continue\n",
    "\n",
    "    baseline_emb = top_baseline = v_baseline\n",
    "    \n",
    "    attributions, predictions = integrated_gradients(emb_inc_program, example_x, example_y, predictions_and_gradients, baseline_emb, steps=100)\n",
    "    subtree_attributions = np.squeeze(np.mean(np.amax(attributions, axis=-1), axis=-1))  # np.squeeze()\n",
    "    top_k_subtrees, top_k_subtree_vals = get_top_k(subtree_attributions, max_k)\n",
    "\n",
    "    top_k_lines, top_k_line_vals, program_length = get_top_k_lines(subtree_attributions, neg_program_id, k=max_k)\n",
    "    \n",
    "    for top_k in [10,5,1]:\n",
    "        c_some_line_found = False\n",
    "        for line in c_all_faulty_lines[neg_program_id][neg_test_id]:\n",
    "            # line level attribution\n",
    "            if line in top_k_lines[:top_k]:\n",
    "                c_faulty_lines_found[top_k][neg_program_id][neg_test_id].add(line)\n",
    "                c_some_line_found = True\n",
    "                           \n",
    "        if c_some_line_found:\n",
    "            c_pairs_localized[top_k].add((neg_program_id,neg_test_id))\n",
    "            c_programs_localized[top_k].add((neg_program_id))\n",
    "        else:\n",
    "            c_pairs_missed[top_k].add((neg_program_id,neg_test_id))\n",
    "        \n",
    "    c_remaining = c_todo_cnt - idx - 1\n",
    "    c_denom = idx+1\n",
    "    \n",
    "    if idx%5==0 and idx>0:\n",
    "        for top_k in [10,5,1]:\n",
    "            print '%d|F:%4d, M:%4d, A:%5.2f%%' % (top_k, len(c_pairs_localized[top_k]), len(c_pairs_missed[top_k]), 100.0*len(c_pairs_localized[top_k])/c_denom),\n",
    "        print '|| CNT:%4d, WP:%3d, EB:%3d \\r' % (c_remaining, len(c_wrong_predictions), len(c_empty_baselines)),\n",
    "        \n",
    "    c_done += 1\n",
    "        \n",
    "for top_k in [10,5,1]:\n",
    "    print '%d|F:%4d, M:%4d, A:%5.2f%%' % (top_k, len(c_pairs_localized[top_k]), len(c_pairs_missed[top_k]), 100.0*len(c_pairs_localized[top_k])/c_denom),\n",
    "print '|| CNT:%4d, WP:%3d, EB:%3d \\r' % (c_remaining, len(c_wrong_predictions), len(c_empty_baselines))\n",
    "\n",
    "print 'skipped:', len(c_skipped), '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_total_pairs = sum(map(len, [c_pairs_localized[top_k], c_pairs_missed[top_k], c_wrong_predictions]))\n",
    "print 'total_pairs:', 10, 5, 1\n",
    "print c_total_pairs, \n",
    "for top_k in [10,5,1]:\n",
    "    print len(c_pairs_localized[top_k]), '%4.2f%%' % (100.0*len(c_pairs_localized[top_k])/c_total_pairs),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_prog_faulty_lines = {}\n",
    "for program_id in c_all_faulty_lines:\n",
    "    if program_id not in c_prog_faulty_lines: c_prog_faulty_lines[program_id] = set()\n",
    "    for test_id in c_all_faulty_lines[program_id]:\n",
    "        c_prog_faulty_lines[program_id].update(c_all_faulty_lines[program_id][test_id])\n",
    "        \n",
    "c_cnt_faulty_lines = 0\n",
    "for program_id in c_prog_faulty_lines:\n",
    "    c_cnt_faulty_lines += len(c_prog_faulty_lines[program_id])\n",
    "\n",
    "c_prog_faulty_lines_found = {10:{},5:{},1:{}}\n",
    "# print c_cnt_faulty_lines,\n",
    "for top_k in [10,5,1]:\n",
    "    for program_id in c_faulty_lines_found[top_k]:\n",
    "        if program_id not in c_prog_faulty_lines_found[top_k]: c_prog_faulty_lines_found[top_k][program_id] = set()\n",
    "        for test_id in c_faulty_lines_found[top_k][program_id]:\n",
    "            c_prog_faulty_lines_found[top_k][program_id].update(c_faulty_lines_found[top_k][program_id][test_id])\n",
    "    \n",
    "    c_cnt_lines_found = 0\n",
    "    for program_id in c_prog_faulty_lines_found[top_k]:\n",
    "        c_cnt_lines_found += len(c_prog_faulty_lines_found[top_k][program_id])\n",
    "\n",
    "#     print c_cnt_lines_found, '%4.2f%%' % (100.0*c_cnt_lines_found/c_cnt_faulty_lines), \n",
    "# print\n",
    "\n",
    "# for programs with more than 1 faulty lines\n",
    "print '\\n', 'Grouped by line diff counts:'\n",
    "c_cnt_faulty_progs, c_cnt_faulty_progs_found = {}, {}\n",
    "c_cnt_faulty_lines, c_cnt_lines_found = {}, {}\n",
    "for top_k in [10,5,1]:\n",
    "    c_cnt_faulty_progs[top_k], c_cnt_faulty_progs_found[top_k] = {'total':0}, {'total':0}\n",
    "    c_cnt_faulty_lines[top_k], c_cnt_lines_found[top_k] = {'total':0}, {'total':0}\n",
    "    for num_buggy_lines in range(1,6):\n",
    "        c_cnt_faulty_progs[top_k][num_buggy_lines], c_cnt_faulty_progs_found[top_k][num_buggy_lines] = 0, 0\n",
    "        c_cnt_faulty_lines[top_k][num_buggy_lines], c_cnt_lines_found[top_k][num_buggy_lines] = 0, 0\n",
    "        for program_id in c_prog_faulty_lines:\n",
    "            if len(c_prog_faulty_lines[program_id]) == num_buggy_lines:\n",
    "                c_cnt_faulty_progs[top_k][num_buggy_lines] += 1\n",
    "                c_cnt_faulty_lines[top_k][num_buggy_lines] += num_buggy_lines\n",
    "                c_cnt_faulty_progs[top_k]['total'] += 1\n",
    "                c_cnt_faulty_lines[top_k]['total'] += num_buggy_lines\n",
    "                \n",
    "                c_cnt_faulty_progs_found[top_k][num_buggy_lines] += 1 if len(c_prog_faulty_lines_found[top_k][program_id]) > 0 else 0\n",
    "                c_cnt_lines_found[top_k][num_buggy_lines] += len(c_prog_faulty_lines_found[top_k][program_id])\n",
    "                c_cnt_faulty_progs_found[top_k]['total'] += 1 if len(c_prog_faulty_lines_found[top_k][program_id]) > 0 else 0\n",
    "                c_cnt_lines_found[top_k]['total'] += len(c_prog_faulty_lines_found[top_k][program_id])\n",
    "                \n",
    "print '\\t\\t\\t\\t top-10 \\t\\t top-5 \\t\\t top-1'\n",
    "print 'diff|progs lines|', '%-22s|' % ('#10 PF \\t #10 LF'), '%-22s|' % ('#5 PF \\t #5 LF'), '%-22s|' % ('#1 PF \\t #1 LF') \n",
    "\n",
    "for key in c_cnt_faulty_lines[10]:    \n",
    "    if c_cnt_faulty_progs[10][key] == 0:\n",
    "        continue\n",
    "    print '{}\\t'.format(key), '%4d %4d' % (c_cnt_faulty_progs[10][key], c_cnt_faulty_lines[10][key]),\n",
    "    for top_k in [10,5,1]:\n",
    "        print '%4d (%6.2f%%)' % (c_cnt_faulty_progs_found[top_k][key], (100.0*c_cnt_faulty_progs_found[top_k][key]/c_cnt_faulty_progs[top_k][key])),\n",
    "        print '%4d (%6.2f%%)' % (c_cnt_lines_found[top_k][key], (100.0*c_cnt_lines_found[top_k][key]/c_cnt_faulty_lines[top_k][key]) ),\n",
    "    print\n",
    "\n",
    "print \n",
    "c_baseline_indices = list(sorted(c_baseline_indices))\n",
    "for percentile in [50,60,70,80,90,95,98,99]:\n",
    "    i = int( percentile * len(c_baseline_indices) / 100.0 )\n",
    "    print 'percentile:', percentile, 'baseline_indices:',  c_baseline_indices[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### results with explicit wrong baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_total_pairs = sum(map(len, [c_pairs_localized[top_k], c_pairs_missed[top_k], c_empty_baselines]))\n",
    "print 'total_pairs', 10, 5, 1\n",
    "print c_total_pairs,\n",
    "for top_k in [10,5,1]:\n",
    "    print len(c_pairs_localized[top_k]), '%4.2f%%' % (100.0*len(c_pairs_localized[top_k])/c_total_pairs),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_prog_faulty_lines = {}\n",
    "for program_id in c_all_faulty_lines:\n",
    "    if program_id not in c_prog_faulty_lines: c_prog_faulty_lines[program_id] = set()\n",
    "    for test_id in c_all_faulty_lines[program_id]:\n",
    "        if (program_id, test_id) not in c_wrong_predictions:\n",
    "            c_prog_faulty_lines[program_id].update(c_all_faulty_lines[program_id][test_id])\n",
    "        \n",
    "c_cnt_faulty_lines = 0\n",
    "for program_id in c_prog_faulty_lines:\n",
    "    c_cnt_faulty_lines += len(c_prog_faulty_lines[program_id])\n",
    "\n",
    "c_prog_faulty_lines_found = {10:{},5:{},1:{}}\n",
    "# print '\\ntotal top-10 top-5 top-1'\n",
    "# print c_cnt_faulty_lines,\n",
    "for top_k in [10,5,1]:\n",
    "    for program_id in c_faulty_lines_found[top_k]:\n",
    "        if program_id not in c_prog_faulty_lines_found[top_k]: c_prog_faulty_lines_found[top_k][program_id] = set()\n",
    "        for test_id in c_faulty_lines_found[top_k][program_id]:\n",
    "            c_prog_faulty_lines_found[top_k][program_id].update(c_faulty_lines_found[top_k][program_id][test_id])\n",
    "    \n",
    "    c_cnt_lines_found = 0\n",
    "    for program_id in c_prog_faulty_lines_found[top_k]:\n",
    "        c_cnt_lines_found += len(c_prog_faulty_lines_found[top_k][program_id])\n",
    "\n",
    "#     print c_cnt_lines_found, '(%5.2f%%)' % (100.0*c_cnt_lines_found/c_cnt_faulty_lines),\n",
    "# print '\\n'\n",
    "\n",
    "print 'Grouped by line diff counts:'\n",
    "c_cnt_faulty_progs, c_cnt_faulty_progs_found = {}, {}\n",
    "c_cnt_faulty_lines, c_cnt_lines_found = {}, {}\n",
    "for top_k in [10,5,1]:\n",
    "    c_cnt_faulty_progs[top_k], c_cnt_faulty_progs_found[top_k] = {'total':0}, {'total':0}\n",
    "    c_cnt_faulty_lines[top_k], c_cnt_lines_found[top_k] = {'total':0}, {'total':0}\n",
    "    for num_buggy_lines in range(1,6):\n",
    "        c_cnt_faulty_progs[top_k][num_buggy_lines], c_cnt_faulty_progs_found[top_k][num_buggy_lines] = 0, 0\n",
    "        c_cnt_faulty_lines[top_k][num_buggy_lines], c_cnt_lines_found[top_k][num_buggy_lines] = 0, 0\n",
    "        for program_id in c_prog_faulty_lines:\n",
    "            if len(c_prog_faulty_lines[program_id]) == num_buggy_lines:\n",
    "                c_cnt_faulty_progs[top_k][num_buggy_lines] += 1\n",
    "                c_cnt_faulty_lines[top_k][num_buggy_lines] += num_buggy_lines\n",
    "                c_cnt_faulty_progs[top_k]['total'] += 1\n",
    "                c_cnt_faulty_lines[top_k]['total'] += num_buggy_lines\n",
    "                \n",
    "                c_cnt_faulty_progs_found[top_k][num_buggy_lines] += 1 if len(c_prog_faulty_lines_found[top_k][program_id]) > 0 else 0\n",
    "                c_cnt_lines_found[top_k][num_buggy_lines] += len(c_prog_faulty_lines_found[top_k][program_id])\n",
    "                c_cnt_faulty_progs_found[top_k]['total'] += 1 if len(c_prog_faulty_lines_found[top_k][program_id]) > 0 else 0\n",
    "                c_cnt_lines_found[top_k]['total'] += len(c_prog_faulty_lines_found[top_k][program_id])\n",
    "                \n",
    "print '\\t\\t\\t\\t top-10 \\t\\t top-5 \\t\\t top-1'\n",
    "print 'diff|progs lines|', '%-22s|' % ('#10 PF \\t #10 LF'), '%-22s|' % ('#5 PF \\t #5 LF'), '%-22s|' % ('#1 PF \\t #1 LF') \n",
    "\n",
    "for key in c_cnt_faulty_lines[10]:    \n",
    "    if c_cnt_faulty_progs[10][key] == 0:\n",
    "        continue\n",
    "    print '{}\\t'.format(key), '%4d %4d' % (c_cnt_faulty_progs[10][key], c_cnt_faulty_lines[10][key]),\n",
    "    for top_k in [10,5,1]:\n",
    "        print '%4d (%6.2f%%)' % (c_cnt_faulty_progs_found[top_k][key], (100.0*c_cnt_faulty_progs_found[top_k][key]/c_cnt_faulty_progs[top_k][key])),\n",
    "        print '%4d (%6.2f%%)' % (c_cnt_lines_found[top_k][key], (100.0*c_cnt_lines_found[top_k][key]/c_cnt_faulty_lines[top_k][key]) ),\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nbl]",
   "language": "python",
   "name": "conda-env-nbl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
